{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d68331",
   "metadata": {},
   "source": [
    "# Evaluating an Azure AI Agent with Azure AI Evaluation SDK\n",
    "\n",
    "GBB learning sessione example to demonstrate how to evaluate an **Azure AI Agent** using three quality metrics provided by the Azure AI Evaluation SDK (preview):\n",
    "1. **Intent Resolution** – Did the agent understand and address the user’s request?\n",
    "2. **Tool Call Accuracy** – Did the agent choose and invoke the correct tool(s) with the right parameters?\n",
    "3. **Task Adherence** – Did the agent follow its instructions and complete the assigned task?\n",
    "\n",
    "Created a mock `fetch_weather` tool, simulate an agent response in various scenarios (correct, incorrect, unspecified / right tool chosen, wrong tool chosen) and evaluate with the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b40947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade azure-ai-projects azure-ai-evaluation azure-identity python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c3cb89",
   "metadata": {},
   "source": [
    "## Setup Azure credentials and project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25458309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and authentication OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# REQUIRED environment variables (replace with your values or a .env file)\n",
    "REQUIRED_KEYS = [\n",
    "    'AZURE_OPENAI_ENDPOINT',\n",
    "    'AZURE_OPENAI_API_KEY',\n",
    "    'AZURE_OPENAI_API_VERSION',\n",
    "    'MODEL_DEPLOYMENT_NAME',\n",
    "    'PROJECT_CONNECTION_STRING',\n",
    "]\n",
    "missing = [k for k in REQUIRED_KEYS if not os.getenv(k)]\n",
    "if missing:\n",
    "    raise EnvironmentError(f'Missing required env keys: {missing}')\n",
    "\n",
    "# Authenticate (interactive fallback)\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "except Exception:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "print('Environment and authentication OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e457e",
   "metadata": {},
   "source": [
    "## Create a sample agent and `fetch_weather` tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478375a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent 'Weather Assistant' with 2 tools\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import FunctionTool, ToolSet\n",
    "import json\n",
    "\n",
    "def fetch_weather(location: str) -> str:\n",
    "    \"\"\"Mock weather service\"\"\"\n",
    "    mock_weather_data = {\n",
    "        'Seattle': 'Sunny, 25°C',\n",
    "        'London': 'Cloudy, 18°C',\n",
    "        'Tokyo': 'Rainy, 22°C'\n",
    "    }\n",
    "    return json.dumps({'weather': mock_weather_data.get(location, 'N/A')})\n",
    "\n",
    "def fetch_funfact(location: str) -> str:\n",
    "    \"\"\"Fun fact about a location\"\"\"\n",
    "    mock_weather_data = {\n",
    "        'Seattle': 'There are whales',\n",
    "        'London': 'Is the capital of England',\n",
    "        'Tokyo': 'Has the highest population density in the world'\n",
    "    }\n",
    "    return json.dumps({'weather': mock_weather_data.get(location, 'N/A')})\n",
    "\n",
    "# Initialize project client with proper authentication\n",
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=credential,  # Use the credential from earlier setup\n",
    "    conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    ")\n",
    "    \n",
    "# Register functions as tools\n",
    "functions = FunctionTool({fetch_weather, fetch_funfact})\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "    \n",
    "# Create agent with proper error handling\n",
    "AGENT_NAME = \"Weather Assistant\"\n",
    "agent = project_client.agents.create_agent(\n",
    "        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "        name=AGENT_NAME,\n",
    "        instructions=\"\"\"You are a helpful weather assistant. When asked about the weather in a location:\n",
    "        1. Use fetch_weather to get current conditions\n",
    "        2. Provide clear, concise responses\n",
    "        3. Stay focused on weather information\n",
    "        Always use tools when available and verify data before responding.\"\"\",\n",
    "        toolset=toolset,\n",
    "    )\n",
    "print(f\"Created agent '{AGENT_NAME}' with {len(functions._functions)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10b321",
   "metadata": {},
   "source": [
    "## Simulate a user query and agent responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72704a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's the weather in Seattle?\n",
      "Agent (correct): The current weather in Seattle is Sunny, 25°C.\n",
      "Agent (incorrect): The weather in Seattle is Rainy, 15°C. In London, it's Sunny, 28°C.\n",
      "\n",
      "User: How much does it rain in Spain?\n",
      "Agent without information, providing irrelevant information\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What's the weather in Seattle?\"\n",
    "user_question_unspecific = \"How much does it rain in Spain?\"\n",
    "\n",
    "# Correct tool usage\n",
    "import json\n",
    "weather_seattle = json.loads(fetch_weather('Seattle'))['weather']\n",
    "weather_london = json.loads(fetch_weather('London'))['weather']\n",
    "agent_response_correct = (\n",
    "    f'The current weather in Seattle is {weather_seattle}.'\n",
    ")\n",
    "\n",
    "# Incorrect tool usage (wrong location)\n",
    "agent_response_incorrect = (\n",
    "    'The weather in Seattle is Rainy, 15°C. In London, it\\'s Sunny, 28°C.'\n",
    ")\n",
    "\n",
    "print('User:', user_question)\n",
    "print('Agent (correct):', agent_response_correct)\n",
    "print('Agent (incorrect):', agent_response_incorrect)\n",
    "\n",
    "print('\\nUser:', user_question_unspecific)\n",
    "print('Agent without information, providing irrelevant information')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f10e8",
   "metadata": {},
   "source": [
    "## Initialize evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9170512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ToolCallAccuracyEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class TaskAdherenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluators setup\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "from azure.ai.evaluation import (\n",
    "    IntentResolutionEvaluator,\n",
    "    ToolCallAccuracyEvaluator,\n",
    "    TaskAdherenceEvaluator,\n",
    ")\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "    api_key=os.environ['AZURE_OPENAI_API_KEY'],\n",
    "    api_version=os.environ['AZURE_OPENAI_API_VERSION'],\n",
    "    azure_deployment=os.environ['MODEL_DEPLOYMENT_NAME'],\n",
    ")\n",
    "\n",
    "intent_eval = IntentResolutionEvaluator(model_config=model_config)\n",
    "tool_eval = ToolCallAccuracyEvaluator(model_config=model_config)\n",
    "task_eval = TaskAdherenceEvaluator(model_config=model_config)\n",
    "print('Evaluators setup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecce7fc",
   "metadata": {},
   "source": [
    "### Intent Resolution\n",
    "\n",
    "Measures how well the agent identifies the user’s request, including how well it scopes the user’s intent, asks clarifying questions, and reminds end users of its scope of capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "698bd77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\n",
      "{'additional_details': {'actual_user_intent': 'get the current weather in Seattle',\n",
      "                        'agent_perceived_intent': 'provide current weather information for Seattle',\n",
      "                        'conversation_has_intent': True,\n",
      "                        'correct_intent_detected': True,\n",
      "                        'intent_resolved': True},\n",
      " 'intent_resolution': 5.0,\n",
      " 'intent_resolution_reason': 'The response accurately provides the current weather in Seattle, including the condition '\n",
      "                             \"and temperature, which directly addresses the user's query about the weather in Seattle.\",\n",
      " 'intent_resolution_result': 'pass',\n",
      " 'intent_resolution_threshold': 3}\n",
      "\n",
      "Incorrect:\n",
      "{'additional_details': {'actual_user_intent': 'get the weather in Seattle',\n",
      "                        'agent_perceived_intent': 'provide weather information for Seattle',\n",
      "                        'conversation_has_intent': True,\n",
      "                        'correct_intent_detected': True,\n",
      "                        'intent_resolved': False},\n",
      " 'intent_resolution': 3.0,\n",
      " 'intent_resolution_reason': 'The response provides the weather information for Seattle, which is relevant to the '\n",
      "                             \"user's query. However, it also includes weather information for London, which is \"\n",
      "                             \"unrelated to the user's request, indicating a lack of focus on the specific intent. The \"\n",
      "                             'response partially addresses the user intent but includes unnecessary information, '\n",
      "                             'leading to a partial resolution.',\n",
      " 'intent_resolution_result': 'pass',\n",
      " 'intent_resolution_threshold': 3}\n",
      "\n",
      "Unspecific:\n",
      "{'additional_details': {'actual_user_intent': 'find out how much it rains in Spain',\n",
      "                        'agent_perceived_intent': 'provide weather information for Seattle and London',\n",
      "                        'conversation_has_intent': True,\n",
      "                        'correct_intent_detected': False,\n",
      "                        'intent_resolved': False},\n",
      " 'intent_resolution': 1.0,\n",
      " 'intent_resolution_reason': \"The agent's response is entirely off-topic, discussing the weather in Seattle and London \"\n",
      "                             'instead of providing any information about rainfall in Spain.',\n",
      " 'intent_resolution_result': 'fail',\n",
      " 'intent_resolution_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "res_intent_correct = intent_eval(query=user_question, response=agent_response_correct)\n",
    "res_intent_incorrect = intent_eval(query=user_question, response=agent_response_incorrect)\n",
    "res_intent_unspecific = intent_eval(query=user_question_unspecific, response=agent_response_incorrect)\n",
    "print('Correct:')\n",
    "pprint(res_intent_correct, width=120, compact=True)\n",
    "print('\\nIncorrect:')\n",
    "pprint(res_intent_incorrect, width=120, compact=True)\n",
    "print('\\nUnspecific:')\n",
    "pprint(res_intent_unspecific, width=120, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6942d",
   "metadata": {},
   "source": [
    "### Tool Call Accuracy\n",
    "\n",
    "Evaluates the agent’s ability to select the appropriate tools, and process correct parameters from previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95491b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\n",
      "{'per_tool_call_details': [{'tool_call_accurate': True,\n",
      "                            'tool_call_accurate_reason': \"The TOOL CALL is directly relevant to the user's query about \"\n",
      "                                                         'the weather in Seattle, uses the correct parameter from the '\n",
      "                                                         'TOOL DEFINITION, and includes the correct parameter value '\n",
      "                                                         'from the CONVERSATION.',\n",
      "                            'tool_call_id': 'call_1'}],\n",
      " 'tool_call_accuracy': 1.0,\n",
      " 'tool_call_accuracy_result': 'pass',\n",
      " 'tool_call_accuracy_threshold': 0.8}\n",
      "\n",
      "Incorrect:\n",
      "{'per_tool_call_details': [{'tool_call_accurate': False,\n",
      "                            'tool_call_accurate_reason': \"The TOOL CALL is irrelevant to the user's query about the \"\n",
      "                                                         'weather in Seattle, uses a parameter value not present or '\n",
      "                                                         'inferred from the conversation, and does not contribute to '\n",
      "                                                         \"resolving the user's need.\",\n",
      "                            'tool_call_id': 'bad_call'}],\n",
      " 'tool_call_accuracy': 0.0,\n",
      " 'tool_call_accuracy_result': 'fail',\n",
      " 'tool_call_accuracy_threshold': 0.8}\n"
     ]
    }
   ],
   "source": [
    "tool_definitions = [\n",
    "    {\n",
    "        'name': 'fetch_weather',\n",
    "        'description': 'Fetches weather information for a location.',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'location': {'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'fetch_funfact',\n",
    "        'description': 'Fetches a fun fact about a location.',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'location': {'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "tool_calls_correct = [\n",
    "    {'type': 'tool_call', 'tool_call_id': 'call_1', 'name': 'fetch_weather', 'arguments': {'location': 'Seattle'}},\n",
    "]\n",
    "tool_calls_incorrect = [\n",
    "    {'type': 'tool_call', 'tool_call_id': 'bad_call', 'name': 'fetch_funfact', 'arguments': {'location': 'Tokyo'}},\n",
    "]\n",
    "\n",
    "res_tool_correct = tool_eval(query=user_question, tool_calls=tool_calls_correct, tool_definitions=tool_definitions)\n",
    "res_tool_incorrect = tool_eval(query=user_question, tool_calls=tool_calls_incorrect, tool_definitions=tool_definitions)\n",
    "\n",
    "\n",
    "print('Correct:')\n",
    "pprint(res_tool_correct, width=120, compact=True)\n",
    "print('\\nIncorrect:')\n",
    "pprint(res_tool_incorrect, width=120, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c40c59",
   "metadata": {},
   "source": [
    "### Task Adherence\n",
    "\n",
    " Measures how well the agent’s final response adheres to its assigned tasks, according to its system message and prior steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762f19c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\n",
      "{'task_adherence': 5.0,\n",
      " 'task_adherence_reason': 'The response accurately provides the current weather in Seattle, including both the '\n",
      "                          \"condition and temperature, which fully adheres to the query's request.\",\n",
      " 'task_adherence_result': 'pass',\n",
      " 'task_adherence_threshold': 3}\n",
      "\n",
      "Incorrect:\n",
      "{'task_adherence': 3.0,\n",
      " 'task_adherence_reason': \"The response meets the core requirement by providing Seattle's weather but lacks precision \"\n",
      "                          \"due to the inclusion of irrelevant information about London's weather.\",\n",
      " 'task_adherence_result': 'pass',\n",
      " 'task_adherence_threshold': 3}\n",
      "\n",
      "Unspecific:\n",
      "{'task_adherence': 1.0,\n",
      " 'task_adherence_reason': \"The response does not address the query about Spain's rainfall at all, instead providing \"\n",
      "                          'unrelated weather information for Seattle and London.',\n",
      " 'task_adherence_result': 'fail',\n",
      " 'task_adherence_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "res_task_correct = task_eval(query=user_question, response=agent_response_correct, tool_calls=tool_calls_correct)\n",
    "res_task_incorrect = task_eval(query=user_question, response=agent_response_incorrect, tool_calls=tool_calls_incorrect)\n",
    "res_task_unspecific = task_eval(query=user_question_unspecific, response=agent_response_incorrect, tool_calls=tool_calls_incorrect)\n",
    "print('Correct:')\n",
    "pprint(res_task_correct, width=120, compact=True)\n",
    "print('\\nIncorrect:')\n",
    "pprint(res_task_incorrect, width=120, compact=True)\n",
    "print('\\nUnspecific:')\n",
    "pprint(res_task_unspecific, width=120, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f8324",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- **Intent Resolution** confirmed the agent understood the request in both scenarios.\n",
    "- **Tool Call Accuracy** detected the incorrect tool usage in the flawed scenario.\n",
    "- **Task Adherence** showed the agent followed instructions even when factual output was wrong.\n",
    "\n",
    "Use these insights to improve your agent’s tool selection logic and answer verification. For production, combine these metrics with others (e.g., factuality, safety) for a complete quality picture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
